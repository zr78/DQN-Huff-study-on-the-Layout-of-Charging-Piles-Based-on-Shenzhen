DQN-Huff-study-on-the-Layout-of-Charging-Piles-Based-on-Shenzhen
# DQN-Huff 模型在深圳市充电桩布局优化中的研究

## 项目描述

本项目旨在解决城市电动汽车充电桩的优化布局问题，提出并实现了一个基于深度强化学习的 DQN-Huff 动态模型。该模型创造性地融合了地理空间分析中经典的 Huff 模型所提供的市场吸引力洞察与 DQN 强化学习算法强大的序列决策能力。通过对深圳市实际数据的案例研究，本项目旨在学习在动态需求和环境变化下，如何在空间上智能地分配充电桩资源，以提高服务效率、满足用户需求并优化资源配置。

## 主要特性

* **Dueling DQN 架构:** 采用 Dueling DQN 网络结构，将 Q 值估计分解为状态值和动作优势流，提升了学习效率和 Q 值估计的准确性。
* **Huff 模型融合:** 将预先计算的充电站吸引力（源自或参考 Huff 模型分析）作为重要的状态特征输入给 DQN，并在奖励函数中设计了基于吸引力和桩数分布的组件，引导智能体学习向高潜力区域倾斜资源。
* **动态环境模拟:** 构建了模拟充电环境，考虑了需求随时间、空间的变化，以及充电桩的容量限制和利用情况。
* **专家知识辅助:** 集成了专家知识系统，可在训练初期辅助生成初始化布局，并可能在一定程度上指导智能体的动作选择（具体实现依赖于 `expert_knowledge.py`）。
* **优先经验回放:** 使用优先经验回放缓冲区存储智能体与环境交互的经验，并根据 TD 误差大小优先采样重要经验，提高了训练效率和稳定性。
* **软更新目标网络:** 采用软更新（Soft Update）机制更新目标网络，相较于硬更新，有助于平滑训练过程。
* **数据加载与预处理:** 包含了加载充电站数据、吸引力数据以及其他相关地理和需求数据的工具（依赖于 `Huff.py` 中的 `UrbanEVDataLoader` 和直接的 CSV 文件读取）。
* **多目标奖励函数:** 设计了综合性的奖励函数，平衡了需求满足度、运营成本、空间均衡性、吸引力匹配度以及 Huff 模型相关的评估指标，引导智能体学习全局最优策略。
* **可视化与结果分析:** 提供了一系列可视化工具，用于展示充电站的地理分布与桩数配置、训练过程中的奖励曲线、损失曲线、Epsilon 衰减曲线以及评估结果。
* **训练检查点:** 支持保存和加载模型检查点，方便中断后恢复训练，并能保存评估表现最佳的模型。

## 环境搭建与安装

1.  **克隆项目仓库：**
    ```bash
    git clone https://github.com/zr78/DQN-Huff-study-on-the-Layout-of-Charging-Piles-Based-on-Shenzhen
    cd DQN-Huff-study-on-the-Layout-of-Charging-Piles-Based-on-Shenzhen
    ```
2.  **安装依赖库：** 本项目依赖于 Python 及以下主要库。推荐使用虚拟环境进行安装。
    ```bash
    pip install torch numpy pandas matplotlib tqdm
    ```
    *注意：你需要确保 `Huff.py` 和 `expert_knowledge.py` 文件存在于项目目录下，或者在 Python 环境中可被正确导入。*
3.  **准备数据：** 在项目根目录下创建 `data` 文件夹，并将项目所需的数据文件放入其中。

## 数据准备

本项目需要特定的数据文件，通常存放在 `./data` 目录下。根据代码结构，以下文件是被预期或使用的：

* `station_inf.csv`: 包含充电站的基础信息，如地理坐标（经纬度）、容量、初始桩数等。
* `station_attractions.csv`: 充电站的吸引力数据，可以是通过 Huff 模型分析或其他方式预计算得到的站点吸引力数值。
* `poi.csv` 或 `poi_data.csv`: 兴趣点 (POI) 数据，可能用于构建简化的路网或辅助需求/吸引力分析。
* `selection_probabilities.csv`: (可选) 预计算的站点选择概率数据，可能用于未来模型改进或参考。
* 其他 UrbanEV 数据集相关的补充文件（由 `Huff.py` 中的 `UrbanEVDataLoader` 处理）。

请确保这些数据文件的格式正确并放置在 `./data` 目录下。

## 使用方法

1.  **配置参数：** 查看并根据需求修改项目根目录下的 `config.json` 文件。该文件包含了训练过程的各种超参数，例如训练回合数、批量大小、学习率、折扣因子、Epsilon 衰减设置、检查点保存频率、专家引导回合数等。
2.  **运行训练：** 执行主训练脚本。
    ```bash
    python DQNtrain_model.py
    ```
    默认情况下，脚本会读取 `config.json` 文件，并尝试从 `./output_dqn_loaded_attr/checkpoints` 目录下加载最新的检查点以恢复训练。你可以通过修改 `DQNtrain_model.py` 文件末尾 `if __name__ == "__main__":` 代码块中的参数来改变数据/输出路径或禁用检查点加载。

## 结果与可视化

训练过程中，脚本会将生成的结果输出到 `config.json` 中指定的输出目录下（默认为 `./output_dqn_loaded_attr`）。输出内容包括：

* **训练日志：** 控制台输出训练进度、奖励、损失等信息。
* **检查点：** 定期保存的模型权重和训练状态，以及评估表现最佳的模型。
* **可视化图表：** PNG 格式的图像文件，包括训练奖励曲线、评估奖励曲线、损失曲线、Epsilon 衰减曲线以及不同训练阶段的充电站布局可视化图。
* **摘要文件：** CSV 格式的文件，总结了特定训练回合时期的充电站布局配置。

这些输出文件可以用于监控训练过程、分析模型性能以及理解智能体学到的布局策略。

## 未来展望

基于当前研究基础和项目进展，未来的工作方向可以包括：

* **融合实际运营数据：** 更紧密地结合真实世界的充电会话、用户行为等动态数据进行模型训练和环境模拟，进一步提升模型的实用性和对现实复杂性的捕捉能力。
* **探索多样化决策风格：** 适配和开发能够生成不同布局策略（如侧重利润最大化、用户公平性或服务特定区域）的模型，以满足城市规划者或运营商的多样化需求。
* **引入多智能体强化学习：** 将大规模充电网络中的各个站点或区域视为协作智能体，采用多智能体强化学习方法来处理站点之间的复杂互动和协同优化问题。

## 作者

zhangrui

*QQ邮箱：2811669184@qq.com*

## 数据链接
百度网盘
通过网盘分享的文件：data.zip
链接: https://pan.baidu.com/s/1O2eptjxZWgzrqso6xBkemQ?pwd=xcbh 提取码: xcbh 
